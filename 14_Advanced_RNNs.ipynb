{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_Advanced_RNNs",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoujiemeng/the-road-of-ML-pytorch-/blob/master/14_Advanced_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Advanced RNNs"
      ]
    },
    {
      "metadata": {
        "id": "OLIxEDq6VhvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "In this notebook we're going to cover some advanced topics related to RNNs.\n",
        "\n",
        "1. Conditioned hidden state\n",
        "2. Char-level embeddings\n",
        "3. Encoder and decoder\n",
        "4. Attentional mechanisms\n",
        "5. Implementation\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "41r7MWJnY0m8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ]
    },
    {
      "metadata": {
        "id": "EJDhjHCHY0_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9b6f8a1-6b84-41c6-8389-e6fbaf15b700"
      },
      "cell_type": "code",
      "source": [
        "# Load PyTorch library\n",
        "!pip3 install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p0FbOd6IZmzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import copy\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOsqAo4XZpXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Numpy and PyTorch seeds\n",
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def create_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHfvEzQ9ZweF",
        "colab_type": "code",
        "outputId": "1b06fa4a-8922-4888-a963-1ee3f6838d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=True,\n",
        "    batch_size=4,\n",
        "    condition_vocab_size=3, # vocabulary for condition possibilities\n",
        "    embedding_dim=100,\n",
        "    rnn_hidden_dim=100,\n",
        "    hidden_dim=100,\n",
        "    num_layers=1,\n",
        "    bidirectional=False,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VoMq0eFRvugb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conditioned RNNs"
      ]
    },
    {
      "metadata": {
        "id": "ZUsj7HjBp69f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conditioning an RNN is to add extra information that will be helpful towards a prediction. We can encode (embed it) this information and feed it along with the sequential input into our model. For example, suppose in our document classificaiton example in the previous notebook, we knew the publisher of each news article (NYTimes, ESPN, etc.). We could have encoded that information to help with the prediction. There are several different ways of creating a conditioned RNN.\n",
        "\n",
        "**Note**: If the conditioning information is novel for each input in the sequence, just concatenate it along with each time step's input."
      ]
    },
    {
      "metadata": {
        "id": "Kc8H9JySmtLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Make the initial hidden state the encoded information instead of using the initial zerod hidden state. Make sure that the size of the encoded information is the same as the hidden state for the RNN.\n"
      ]
    },
    {
      "metadata": {
        "id": "pKlb9SjfpbED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/conditioned_rnn1.png\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "jbrlQHx2x8Aa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFoiV-fqmvRo",
        "colab_type": "code",
        "outputId": "5f642b7c-89c6-44b0-d6c6-da1c60fe9739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Condition\n",
        "condition = torch.LongTensor([0, 2, 1, 2]) # batch size of 4 with a vocab size of 3\n",
        "condition_embeddings = nn.Embedding(\n",
        "    embedding_dim=args.embedding_dim, # should be same as RNN hidden dim\n",
        "    num_embeddings=args.condition_vocab_size) # of unique conditions\n",
        "\n",
        "# Initialize hidden state\n",
        "num_directions = 1\n",
        "if args.bidirectional:\n",
        "    num_directions = 2\n",
        "    \n",
        "# If using multiple layers and directions, the hidden state needs to match that size\n",
        "hidden_t = condition_embeddings(condition).unsqueeze(0).repeat(\n",
        "    args.num_layers * num_directions, 1, 1).to(args.device) # initial state to RNN\n",
        "print (hidden_t.size())\n",
        "\n",
        "# Feed into RNN\n",
        "# y_out, _ = self.rnn(x_embedded, hidden_t)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REgyaMDgmtHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Concatenate the encoded information with the hidden state at each time step. Do not replace the hidden state because the RNN needs that to learn. "
      ]
    },
    {
      "metadata": {
        "id": "yUIg5o-dpiZF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/conditioned_rnn2.png\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "eQ-h28o-pi4X",
        "colab_type": "code",
        "outputId": "449d1faf-ccf5-4a04-d8c0-233e9577dd54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize hidden state\n",
        "hidden_t = torch.zeros((args.num_layers * num_directions, args.batch_size, args.rnn_hidden_dim))\n",
        "print (hidden_t.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Z6hYSIdqBQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concat_condition(condition_embeddings, condition, hidden_t, num_layers, num_directions):\n",
        "    condition_t = condition_embeddings(condition).unsqueeze(0).repeat(\n",
        "        num_layers * num_directions, 1, 1)\n",
        "    hidden_t = torch.cat([hidden_t, condition_t], 2)\n",
        "    return hidden_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tjyzq_s5pixL",
        "colab_type": "code",
        "outputId": "31445f27-0baf-4668-8b0a-2712065f20f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Loop through the inputs time steps\n",
        "hiddens = []\n",
        "seq_size = 1\n",
        "for t in range(seq_size):\n",
        "    hidden_t = concat_condition(condition_embeddings, condition, hidden_t, \n",
        "                                args.num_layers, num_directions).to(args.device)\n",
        "    print (hidden_t.size())\n",
        "    \n",
        "    # Feed into RNN\n",
        "    # hidden_t = rnn_cell(x_in[t], hidden_t)\n",
        "    ..."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A-0_81jMXg_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Char-level embeddings"
      ]
    },
    {
      "metadata": {
        "id": "w0yUKKpq3pu_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our conv operations will have inputs that are words in a sentence represented at the character level|  $\\in \\mathbb{R}^{NXSXWXE}$  and outputs are embeddings for each word (based on convlutions applied at the character level.) \n",
        "\n",
        "**Word embeddings**: capture the temporal correlations among\n",
        "adjacent tokens so that similar words have similar representations. Ex. \"New Jersey\" is close to \"NJ\" is close to \"Garden State\", etc.\n",
        "\n",
        "**Char embeddings**: create representations that map words at a character level. Ex. \"toy\" and \"toys\" will be close to each other."
      ]
    },
    {
      "metadata": {
        "id": "-SZgVuwebm_4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/char_embeddings.png\" width=450>"
      ]
    },
    {
      "metadata": {
        "id": "QOdIvz0G3O8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=False,\n",
        "    shuffle=True,\n",
        "    batch_size=64,\n",
        "    vocab_size=20, # vocabulary\n",
        "    seq_size=10, # max length of each sentence\n",
        "    word_size=15, # max length of each word\n",
        "    embedding_dim=100,\n",
        "    num_filters=100, # filters per size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raztXIeYXYJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_embeddings, num_input_channels, \n",
        "                 num_output_channels, padding_idx):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        # Char-level embedding\n",
        "        self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                       num_embeddings=num_embeddings,\n",
        "                                       padding_idx=padding_idx)\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, num_output_channels, \n",
        "                                             kernel_size=f) for f in [2,3,4]])\n",
        "\n",
        "    def forward(self, x, channel_first=False, apply_softmax=False):\n",
        "        \n",
        "        # x: (N, seq_len, word_len)\n",
        "        input_shape = x.size()\n",
        "        batch_size, seq_len, word_len = input_shape\n",
        "        x = x.view(-1, word_len) # (N*seq_len, word_len)\n",
        "        \n",
        "        # Embedding\n",
        "        x = self.embeddings(x) # (N*seq_len, word_len, embedding_dim)\n",
        "        \n",
        "        # Rearrange input so num_input_channels is in dim 1 (N, embedding_dim, word_len)\n",
        "        if not channel_first:\n",
        "            x = x.transpose(1, 2)\n",
        "        \n",
        "        # Convolution\n",
        "        z = [F.relu(conv(x)) for conv in self.conv]\n",
        "        \n",
        "        # Pooling\n",
        "        z = [F.max_pool1d(zz, zz.size(2)).squeeze(2) for zz in z] \n",
        "        z = [zz.view(batch_size, seq_len, -1) for zz in z] # (N, seq_len, embedding_dim)\n",
        "        \n",
        "        # Concat to get char-level embeddings\n",
        "        z = torch.cat(z, 2) # join conv outputs\n",
        "        \n",
        "        return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MzHVs8Xe0Zph",
        "colab_type": "code",
        "outputId": "d3a5ba80-ba74-42b5-aae7-5074796c99cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Input\n",
        "input_size = (args.batch_size, args.seq_size, args.word_size)\n",
        "x_in = torch.randint(low=0, high=args.vocab_size, size=input_size).long()\n",
        "print (x_in.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0B_Xscby2PMQ",
        "colab_type": "code",
        "outputId": "bb3b18f6-f4da-4378-b138-bb2fa1f60e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "# Initial char-level embedding model\n",
        "model = Model(embedding_dim=args.embedding_dim, \n",
        "              num_embeddings=args.vocab_size, \n",
        "              num_input_channels=args.embedding_dim, \n",
        "              num_output_channels=args.num_filters,\n",
        "              padding_idx=0)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_modules of Model(\n",
            "  (embeddings): Embedding(20, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 100, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DIgeEZFXYR2",
        "colab_type": "code",
        "outputId": "41b6b6ca-5d9f-4b67-954f-6f3d9308bfaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Forward pass to get char-level embeddings\n",
        "z = model(x_in)\n",
        "print (z.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzTscaE10HFA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are several different ways you can use these char-level embeddings:\n",
        "\n",
        "1. Concat char-level embeddings with word-level embeddings, since we have an embedding for each word (at a char-level) and then feed it into an RNN. \n",
        "2. You can feed the char-level embeddings into an RNN to processes them."
      ]
    },
    {
      "metadata": {
        "id": "nyCQ13_ckV_c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Encoder and decoder"
      ]
    },
    {
      "metadata": {
        "id": "_sixbu74kbJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So far we've used RNNs to `encode` a sequential input and generate hidden states. We use these hidden states to `decode` the predictions. So far, the encoder was an RNN and the decoder was just a few fully connected layers followed by a softmax layer (for classification). But the encoder and decoder can assume other architectures as well. For example, the decoder could be an RNN that processes the hidden state outputs from the encoder RNN. "
      ]
    },
    {
      "metadata": {
        "id": "kfK1mAp1dlpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "args = Namespace(\n",
        "    batch_size=64,\n",
        "    embedding_dim=100,\n",
        "    rnn_hidden_dim=100,\n",
        "    hidden_dim=100,\n",
        "    num_layers=1,\n",
        "    bidirectional=False,\n",
        "    dropout=0.1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_OJFyY97bF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_embeddings, rnn_hidden_dim, \n",
        "                 num_layers, bidirectional, padding_idx=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # Embeddings\n",
        "        self.word_embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                            num_embeddings=num_embeddings,\n",
        "                                            padding_idx=padding_idx)\n",
        "        \n",
        "        # GRU weights\n",
        "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=rnn_hidden_dim, \n",
        "                          num_layers=num_layers, batch_first=True, \n",
        "                          bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, x_in, x_lengths):\n",
        "        \n",
        "        # Word level embeddings\n",
        "        z_word = self.word_embeddings(x_in)\n",
        "   \n",
        "        # Feed into RNN\n",
        "        out, h_n = self.gru(z)\n",
        "        \n",
        "        # Gather the last relevant hidden state\n",
        "        out = gather_last_relevant_hidden(out, x_lengths)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRXtaGPlpyH7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, rnn_hidden_dim, hidden_dim, output_dim, dropout_p):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, encoder_output, apply_softmax=False):\n",
        "        \n",
        "        # FC layers\n",
        "        z = self.dropout(encoder_output)\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnKyCPVj-OVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_embeddings, rnn_hidden_dim, \n",
        "                 hidden_dim, num_layers, bidirectional, output_dim, dropout_p, \n",
        "                 padding_idx=0):\n",
        "        super(Model, self).__init__()\n",
        "        self.encoder = Encoder(embedding_dim, num_embeddings, rnn_hidden_dim, \n",
        "                               num_layers, bidirectional, padding_idx=0)\n",
        "        self.decoder = Decoder(rnn_hidden_dim, hidden_dim, output_dim, dropout_p)\n",
        "        \n",
        "    def forward(self, x_in, x_lengths, apply_softmax=False):\n",
        "        encoder_outputs = self.encoder(x_in, x_lengths)\n",
        "        y_pred = self.decoder(encoder_outputs, apply_softmax)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfeoErsc-Tum",
        "colab_type": "code",
        "outputId": "b332272a-9c75-42ee-80d3-6d2545c1d457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(embedding_dim=args.embedding_dim, num_embeddings=1000, \n",
        "              rnn_hidden_dim=args.rnn_hidden_dim, hidden_dim=args.hidden_dim, \n",
        "              num_layers=args.num_layers, bidirectional=args.bidirectional, \n",
        "              output_dim=4, dropout_p=args.dropout, padding_idx=0)\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of Model(\n",
            "  (encoder): Encoder(\n",
            "    (word_embeddings): Embedding(1000, 100, padding_idx=0)\n",
            "    (gru): GRU(100, 100, batch_first=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (dropout): Dropout(p=0.1)\n",
            "    (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            "  )\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LAsOI6jEmTd0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attentional mechanisms"
      ]
    },
    {
      "metadata": {
        "id": "vJN5ft5Sc_kb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When processing an input sequence with an RNN, recall that at each time step we process the input and the hidden state at that time step. For many use cases, it's advantageous to have access to the inputs at all time steps and pay selective attention to the them at each time step. For example, in machine translation, it's advantageous to have access to all the words when translating to another language because translations aren't necessarily word for word. "
      ]
    },
    {
      "metadata": {
        "id": "jb6A6WfbXje6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/attention1.jpg\" width=650>"
      ]
    },
    {
      "metadata": {
        "id": "mNkayU0rf-ua",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Attention can sound a bit confusing so let's see what happens at each time step. At time step j, the model has processed inputs $x_0, x_1, x_2, ..., x_j$ and has generted hidden states $h_0, h_1, h_2, ..., h_j$. The idea is to use all the processed hidden states to make the prediction and not just the most recent one. There are several approaches to how we can do this.\n",
        "\n",
        "With **soft attention**, we learn a vector of floating points (probabilities) to multiply with the hidden states to create the context vector.\n",
        "\n",
        "Ex. [0.1, 0.3, 0.1, 0.4, 0.1]\n",
        "\n",
        "With **hard attention**, we can learn a binary vector to multiply with the hidden states to create the context vector. \n",
        "\n",
        "Ex. [0, 0, 0, 1, 0]"
      ]
    },
    {
      "metadata": {
        "id": "gYSIAVQqu3Ab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to focus on soft attention because it's more widley used and we can visualize how much of each hidden state helps with the prediction, which is great for interpretability. "
      ]
    },
    {
      "metadata": {
        "id": "9Ch21nZNvDHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/attention2.jpg\" width=650>"
      ]
    },
    {
      "metadata": {
        "id": "o_jPXuT8xlqd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to implement attention in the document classification task below."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0iNnQzdxnGvn"
      },
      "cell_type": "markdown",
      "source": [
        "# Document classification with RNNs"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n38ZJoVZnGaE"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to implement the same document classification task as in the previous notebook but we're going to use an attentional interface for interpretability.\n",
        "\n",
        "**Why not machine translation?** Normally, machine translation is the go-to example for demonstrating attention but it's not really practical. How many situations can you think of that require a seq to generate another sequence? Instead we're going to apply attention with our document classification example to see which input tokens are more influential towards predicting the genre."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Fu7HgEqbnGFY"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "elL6BxtCmNGf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "import collections\n",
        "import copy\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DCf2fLmPbKKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_seeds(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "# Creating directories\n",
        "def create_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5fe4ae68-5c22-4340-983b-38d81419ff9f",
        "id": "TTwkuoZdmMlF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "args = Namespace(\n",
        "    seed=1234,\n",
        "    cuda=True,\n",
        "    shuffle=True,\n",
        "    data_file=\"news.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"news\",\n",
        "    train_size=0.7,\n",
        "    val_size=0.15,\n",
        "    test_size=0.15,\n",
        "    pretrained_embeddings=None,\n",
        "    cutoff=25,\n",
        "    num_epochs=5,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=128,\n",
        "    embedding_dim=100,\n",
        "    kernels=[3,5],\n",
        "    num_filters=100,\n",
        "    rnn_hidden_dim=128,\n",
        "    hidden_dim=200,\n",
        "    num_layers=1,\n",
        "    bidirectional=False,\n",
        "    dropout_p=0.25,\n",
        ")\n",
        "\n",
        "# Set seeds\n",
        "set_seeds(seed=args.seed, cuda=args.cuda)\n",
        "\n",
        "# Create save dir\n",
        "create_dirs(args.save_dir)\n",
        "\n",
        "# Expand filepaths\n",
        "args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
        "args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xfiWhgX5mMQ5"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "baAsxXNFmMCF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3tJi_HyOmLw-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/data/news.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(args.data_file, 'wb') as fp:\n",
        "    fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "225bf7e3-2637-403c-d015-011a7854936f",
        "id": "wrI_df4bmLjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(args.data_file, header=0)\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                              title\n",
              "0  Business  Wall St. Bears Claw Back Into the Black (Reuters)\n",
              "1  Business  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
              "2  Business    Oil and Economy Cloud Stocks' Outlook (Reuters)\n",
              "3  Business  Iraq Halts Oil Exports from Main Southern Pipe...\n",
              "4  Business  Oil prices soar to all-time record, posing new..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6098982c-1830-43d5-a4e8-9bda8687c78a",
        "id": "TreK7nqEmLTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "by_category = collections.defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    by_category[row.category].append(row.to_dict())\n",
        "for category in by_category:\n",
        "    print (\"{0}: {1}\".format(category, len(by_category[category])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Business: 30000\n",
            "Sci/Tech: 30000\n",
            "Sports: 30000\n",
            "World: 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "35nb3LxLmLCA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_list = []\n",
        "for _, item_list in sorted(by_category.items()):\n",
        "    if args.shuffle:\n",
        "        np.random.shuffle(item_list)\n",
        "    n = len(item_list)\n",
        "    n_train = int(args.train_size*n)\n",
        "    n_val = int(args.val_size*n)\n",
        "    n_test = int(args.test_size*n)\n",
        "\n",
        "  # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "    for item in item_list[n_train+n_val:]:\n",
        "        item['split'] = 'test'  \n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "05a1ac95-4b1d-450a-9afb-5710da4f37df",
        "id": "Y48IvuSfmK07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "split_df = pd.DataFrame(final_list)\n",
        "split_df[\"split\"].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    84000\n",
              "val      18000\n",
              "test     18000\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RWuNBxAXmKk2",
        "outputId": "12db7b70-e3f3-4e08-83e5-a107165daeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "    \n",
        "split_df.title = split_df.title.apply(preprocess_text)\n",
        "split_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>split</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>general electric posts higher rd quarter profit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>lilly to eliminate up to us jobs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>s amp p lowers america west outlook to negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>does rand walk the talk on labor policy ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business</td>\n",
              "      <td>train</td>\n",
              "      <td>housekeeper advocates for changes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category  split                                            title\n",
              "0  Business  train  general electric posts higher rd quarter profit\n",
              "1  Business  train                 lilly to eliminate up to us jobs\n",
              "2  Business  train  s amp p lowers america west outlook to negative\n",
              "3  Business  train        does rand walk the talk on labor policy ?\n",
              "4  Business  train                housekeeper advocates for changes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "m-a0OpqhmKJc"
      },
      "cell_type": "markdown",
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RUMQ_MwumJ8F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None):\n",
        "\n",
        "        # Token to index\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'token_to_idx': self.token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token[token] for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LtYf3lpExBb",
        "colab_type": "code",
        "outputId": "ca8688cd-baa2-4bd2-8fdd-1ca45aa51837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Vocabulary instance\n",
        "category_vocab = Vocabulary()\n",
        "for index, row in df.iterrows():\n",
        "    category_vocab.add_token(row.category)\n",
        "print (category_vocab) # __str__\n",
        "print (len(category_vocab)) # __len__\n",
        "index = category_vocab.lookup_token(\"Business\")\n",
        "print (index)\n",
        "print (category_vocab.lookup_index(index))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary(size=4)>\n",
            "4\n",
            "0\n",
            "Business\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0zkF6CsE_yH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequence vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "QtntaISyE_1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we're going to create our Vocabulary classes for the article's title, which is a sequence of words."
      ]
    },
    {
      "metadata": {
        "id": "ovI8QRefEw_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4W3ZouuTEw1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self.mask_token = mask_token\n",
        "        self.unk_token = unk_token\n",
        "        self.begin_seq_token = begin_seq_token\n",
        "        self.end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self.mask_token)\n",
        "        self.unk_index = self.add_token(self.unk_token)\n",
        "        self.begin_seq_index = self.add_token(self.begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self.end_seq_token)\n",
        "        \n",
        "        # Index to token\n",
        "        self.idx_to_token = {idx: token \\\n",
        "                             for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self.unk_token,\n",
        "                         'mask_token': self.mask_token,\n",
        "                         'begin_seq_token': self.begin_seq_token,\n",
        "                         'end_seq_token': self.end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx.get(token, self.unk_index)\n",
        "    \n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the SequenceVocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "    \n",
        "    def __str__(self):\n",
        "        return \"<SequenceVocabulary(size=%d)>\" % len(self.token_to_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5UHjpi3El37",
        "colab_type": "code",
        "outputId": "31f9deb4-dbe2-49ad-f65a-c0a703057a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Get word counts\n",
        "word_counts = Counter()\n",
        "for title in split_df.title:\n",
        "    for token in title.split(\" \"):\n",
        "        if token not in string.punctuation:\n",
        "            word_counts[token] += 1\n",
        "\n",
        "# Create SequenceVocabulary instance\n",
        "title_word_vocab = SequenceVocabulary()\n",
        "for word, word_count in word_counts.items():\n",
        "    if word_count >= args.cutoff:\n",
        "        title_word_vocab.add_token(word)\n",
        "print (title_word_vocab) # __str__\n",
        "print (len(title_word_vocab)) # __len__\n",
        "index = title_word_vocab.lookup_token(\"general\")\n",
        "print (index)\n",
        "print (title_word_vocab.lookup_index(index))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SequenceVocabulary(size=4400)>\n",
            "4400\n",
            "4\n",
            "general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1_wja0EfQNpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're also going to create an instance fo SequenceVocabulary that processes the input on a character level."
      ]
    },
    {
      "metadata": {
        "id": "5SpfS0BXP9pz",
        "colab_type": "code",
        "outputId": "2771c4cf-804a-4748-850d-ea0cf6b56cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Create SequenceVocabulary instance\n",
        "title_char_vocab = SequenceVocabulary()\n",
        "for title in split_df.title:\n",
        "    for token in title:\n",
        "        title_char_vocab.add_token(token)\n",
        "print (title_char_vocab) # __str__\n",
        "print (len(title_char_vocab)) # __len__\n",
        "index = title_char_vocab.lookup_token(\"g\")\n",
        "print (index)\n",
        "print (title_char_vocab.lookup_index(index))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SequenceVocabulary(size=35)>\n",
            "35\n",
            "4\n",
            "g\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Dag6H0SFHAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "VQIfxcUuKwzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Something new that we introduce in this Vectorizer is calculating the length of our input sequence. We will use this later on to extract the last relevant hidden state for each input sequence."
      ]
    },
    {
      "metadata": {
        "id": "tsNtEnhBEl6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsVectorizer(object):\n",
        "    def __init__(self, title_word_vocab, title_char_vocab, category_vocab):\n",
        "        self.title_word_vocab = title_word_vocab\n",
        "        self.title_char_vocab = title_char_vocab\n",
        "        self.category_vocab = category_vocab\n",
        "\n",
        "    def vectorize(self, title):\n",
        "       \n",
        "        # Word-level vectorization\n",
        "        word_indices = [self.title_word_vocab.lookup_token(token) for token in title.split(\" \")]\n",
        "        word_indices = [self.title_word_vocab.begin_seq_index] + word_indices + \\\n",
        "            [self.title_word_vocab.end_seq_index]\n",
        "        title_length = len(word_indices)\n",
        "        word_vector = np.zeros(title_length, dtype=np.int64)\n",
        "        word_vector[:len(word_indices)] = word_indices\n",
        "        \n",
        "        # Char-level vectorization\n",
        "        word_length = max([len(word) for word in title.split(\" \")])\n",
        "        char_vector = np.zeros((len(word_vector), word_length), dtype=np.int64)\n",
        "        char_vector[0, :] = self.title_word_vocab.mask_index # <BEGIN>\n",
        "        char_vector[-1, :] = self.title_word_vocab.mask_index # <END>\n",
        "        for i, word in enumerate(title.split(\" \")):\n",
        "            char_vector[i+1,:len(word)] = [title_char_vocab.lookup_token(char) \\\n",
        "                                           for char in word] # i+1 b/c of <BEGIN> token\n",
        "                \n",
        "        return word_vector, char_vector, len(word_indices)\n",
        "    \n",
        "    def unvectorize_word_vector(self, word_vector):\n",
        "        tokens = [self.title_word_vocab.lookup_index(index) for index in word_vector]\n",
        "        title = \" \".join(token for token in tokens)\n",
        "        return title\n",
        "    \n",
        "    def unvectorize_char_vector(self, char_vector):\n",
        "        title = \"\"\n",
        "        for word_vector in char_vector:\n",
        "            for index in word_vector:\n",
        "                if index == self.title_char_vocab.mask_index:\n",
        "                    break\n",
        "                title += self.title_char_vocab.lookup_index(index)\n",
        "            title += \" \"\n",
        "        return title\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, cutoff):\n",
        "        \n",
        "        # Create class vocab\n",
        "        category_vocab = Vocabulary()        \n",
        "        for category in sorted(set(df.category)):\n",
        "            category_vocab.add_token(category)\n",
        "\n",
        "        # Get word counts\n",
        "        word_counts = Counter()\n",
        "        for title in df.title:\n",
        "            for token in title.split(\" \"):\n",
        "                word_counts[token] += 1\n",
        "        \n",
        "        # Create title vocab (word level)\n",
        "        title_word_vocab = SequenceVocabulary()\n",
        "        for word, word_count in word_counts.items():\n",
        "            if word_count >= cutoff:\n",
        "                title_word_vocab.add_token(word)\n",
        "                \n",
        "        # Create title vocab (char level)\n",
        "        title_char_vocab = SequenceVocabulary()\n",
        "        for title in df.title:\n",
        "            for token in title:\n",
        "                title_char_vocab.add_token(token)\n",
        "        \n",
        "        return cls(title_word_vocab, title_char_vocab, category_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        title_word_vocab = SequenceVocabulary.from_serializable(contents['title_word_vocab'])\n",
        "        title_char_vocab = SequenceVocabulary.from_serializable(contents['title_char_vocab'])\n",
        "        category_vocab = Vocabulary.from_serializable(contents['category_vocab'])\n",
        "        return cls(title_word_vocab=title_word_vocab, \n",
        "                   title_char_vocab=title_char_vocab, \n",
        "                   category_vocab=category_vocab)\n",
        "    \n",
        "    def to_serializable(self):\n",
        "        return {'title_word_vocab': self.title_word_vocab.to_serializable(),\n",
        "                'title_char_vocab': self.title_char_vocab.to_serializable(),\n",
        "                'category_vocab': self.category_vocab.to_serializable()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JtRRXU53El9Y",
        "colab_type": "code",
        "outputId": "45e05a3f-9da6-405f-84b1-6c36d14c81c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Vectorizer instance\n",
        "vectorizer = NewsVectorizer.from_dataframe(split_df, cutoff=args.cutoff)\n",
        "print (vectorizer.title_word_vocab)\n",
        "print (vectorizer.title_char_vocab)\n",
        "print (vectorizer.category_vocab)\n",
        "word_vector, char_vector, title_length = vectorizer.vectorize(preprocess_text(\n",
        "    \"Roger Federer wins the Wimbledon tennis tournament.\"))\n",
        "print (\"word_vector:\", np.shape(word_vector))\n",
        "print (\"char_vector:\", np.shape(char_vector))\n",
        "print (\"title_length:\", title_length)\n",
        "print (word_vector)\n",
        "print (char_vector)\n",
        "print (vectorizer.unvectorize_word_vector(word_vector))\n",
        "print (vectorizer.unvectorize_char_vector(char_vector))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SequenceVocabulary(size=4404)>\n",
            "<SequenceVocabulary(size=35)>\n",
            "<Vocabulary(size=4)>\n",
            "word_vector: (10,)\n",
            "char_vector: (10, 10)\n",
            "title_length: 10\n",
            "[   2    1 4151 1231   25    1 2392 4076   38    3]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 7 15  4  5  7  0  0  0  0  0]\n",
            " [21  5 18  5  7  5  7  0  0  0]\n",
            " [26 13  6 16  0  0  0  0  0  0]\n",
            " [12 17  5  0  0  0  0  0  0  0]\n",
            " [26 13 23 25  9  5 18 15  6  0]\n",
            " [12  5  6  6 13 16  0  0  0  0]\n",
            " [12 15 20  7  6  8 23  5  6 12]\n",
            " [30  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]]\n",
            "<BEGIN> <UNK> federer wins the <UNK> tennis tournament . <END>\n",
            " roger federer wins the wimbledon tennis tournament .  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uk_QvpVfFM0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ]
    },
    {
      "metadata": {
        "id": "oU7oDdelFMR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pB7FHmiSFMXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "\n",
        "        # Data splits\n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.val_size = len(self.val_df)\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        self.lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                            'val': (self.val_df, self.val_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights (for imbalances)\n",
        "        class_counts = df.category.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self.vectorizer.category_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, df, cutoff):\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, NewsVectorizer.from_dataframe(train_df, cutoff))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, df, vectorizer_filepath):\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(df, vectorizer)\n",
        "\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return NewsVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self.vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self.target_split = split\n",
        "        self.target_df, self.target_size = self.lookup_dict[split]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(split={0}, size={1})\".format(\n",
        "            self.target_split, self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.target_df.iloc[index]\n",
        "        title_word_vector, title_char_vector, title_length = \\\n",
        "            self.vectorizer.vectorize(row.title)\n",
        "        category_index = self.vectorizer.category_vocab.lookup_token(row.category)\n",
        "        return {'title_word_vector': title_word_vector, \n",
        "                'title_char_vector': title_char_vector, \n",
        "                'title_length': title_length, \n",
        "                'category': category_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, collate_fn, shuffle=True, \n",
        "                         drop_last=False, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size,\n",
        "                                collate_fn=collate_fn, shuffle=shuffle, \n",
        "                                drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Dpb6ZHJFMeb",
        "colab_type": "code",
        "outputId": "caf0a1f3-7972-416f-96dc-edaa480c743d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "# Dataset instance\n",
        "dataset = NewsDataset.load_dataset_and_make_vectorizer(df=split_df,\n",
        "                                                       cutoff=args.cutoff)\n",
        "print (dataset) # __str__\n",
        "input_ = dataset[10] # __getitem__\n",
        "print (input_['title_word_vector'])\n",
        "print (input_['title_char_vector'])\n",
        "print (input_['title_length'])\n",
        "print (input_['category'])\n",
        "print (dataset.vectorizer.unvectorize_word_vector(input_['title_word_vector']))\n",
        "print (dataset.vectorizer.unvectorize_char_vector(input_['title_char_vector']))\n",
        "print (dataset.class_weights)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Dataset(split=train, size=84000)\n",
            "[ 2 51  1 52 53 26 54  3]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0]\n",
            " [18  5  9 12  8  0  0  0  0  0]\n",
            " [18 15 18  4  5 16  0  0  0  0]\n",
            " [25  8  6 27  7 20 14 12 11 22]\n",
            " [26 13 12 17  0  0  0  0  0  0]\n",
            " [ 9  8 25 15  7  0  0  0  0  0]\n",
            " [18  5  8  9  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]]\n",
            "8\n",
            "0\n",
            "<BEGIN> delta <UNK> bankruptcy with labor deal <END>\n",
            " delta dodges bankruptcy with labor deal  \n",
            "tensor([3.3333e-05, 3.3333e-05, 3.3333e-05, 3.3333e-05])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IUIqtbvFUAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "xJV5WlDiFVVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "embed → encoder → attend → predict"
      ]
    },
    {
      "metadata": {
        "id": "rZCzdZZ9FMhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c9wipRZt7feC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_word_embeddings, num_char_embeddings,\n",
        "                 kernels, num_input_channels, num_output_channels, \n",
        "                 rnn_hidden_dim, num_layers, bidirectional, \n",
        "                 word_padding_idx=0, char_padding_idx=0):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        \n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        # Embeddings\n",
        "        self.word_embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                            num_embeddings=num_word_embeddings,\n",
        "                                            padding_idx=word_padding_idx)\n",
        "        self.char_embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                            num_embeddings=num_char_embeddings,\n",
        "                                            padding_idx=char_padding_idx)\n",
        "        \n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList([nn.Conv1d(num_input_channels, \n",
        "                                             num_output_channels, \n",
        "                                             kernel_size=f) for f in kernels])\n",
        "        \n",
        "        \n",
        "        # GRU weights\n",
        "        self.gru = nn.GRU(input_size=embedding_dim*(len(kernels)+1), \n",
        "                          hidden_size=rnn_hidden_dim, num_layers=num_layers, \n",
        "                          batch_first=True, bidirectional=bidirectional)\n",
        "        \n",
        "    def initialize_hidden_state(self, batch_size, rnn_hidden_dim, device):\n",
        "        \"\"\"Modify this to condition the RNN.\"\"\"\n",
        "        num_directions = 1\n",
        "        if self.bidirectional:\n",
        "            num_directions = 2\n",
        "        hidden_t = torch.zeros(self.num_layers * num_directions, \n",
        "                               batch_size, rnn_hidden_dim).to(device)\n",
        "        \n",
        "    def get_char_level_embeddings(self, x):\n",
        "        # x: (N, seq_len, word_len)\n",
        "        input_shape = x.size()\n",
        "        batch_size, seq_len, word_len = input_shape\n",
        "        x = x.view(-1, word_len) # (N*seq_len, word_len)\n",
        "        \n",
        "        # Embedding\n",
        "        x = self.char_embeddings(x) # (N*seq_len, word_len, embedding_dim)\n",
        "        \n",
        "        # Rearrange input so num_input_channels is in dim 1 (N, embedding_dim, word_len)\n",
        "        x = x.transpose(1, 2)\n",
        "        \n",
        "        # Convolution\n",
        "        z = [F.relu(conv(x)) for conv in self.conv]\n",
        "        \n",
        "        # Pooling\n",
        "        z = [F.max_pool1d(zz, zz.size(2)).squeeze(2) for zz in z] \n",
        "        z = [zz.view(batch_size, seq_len, -1) for zz in z] # (N, seq_len, embedding_dim)\n",
        "        \n",
        "        # Concat to get char-level embeddings\n",
        "        z = torch.cat(z, 2) # join conv outputs\n",
        "        \n",
        "        return z\n",
        "        \n",
        "    def forward(self, x_word, x_char, x_lengths, device):\n",
        "        \"\"\"\n",
        "        x_word: word level representation (N, seq_size)\n",
        "        x_char: char level representation (N, seq_size, word_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        # Word level embeddings\n",
        "        z_word = self.word_embeddings(x_word)\n",
        "        \n",
        "        # Char level embeddings\n",
        "        z_char = self.get_char_level_embeddings(x=x_char)\n",
        "        \n",
        "        # Concatenate\n",
        "        z = torch.cat([z_word, z_char], 2)\n",
        "        \n",
        "        # Feed into RNN\n",
        "        initial_h = self.initialize_hidden_state(\n",
        "            batch_size=z.size(0), rnn_hidden_dim=self.gru.hidden_size,\n",
        "            device=device)\n",
        "        out, h_n = self.gru(z, initial_h)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeEcdA287gz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsDecoder(nn.Module):\n",
        "    def __init__(self, rnn_hidden_dim, hidden_dim, output_dim, dropout_p):\n",
        "        super(NewsDecoder, self).__init__()\n",
        "        \n",
        "        # Attention FC layer\n",
        "        self.fc_attn = nn.Linear(rnn_hidden_dim, rnn_hidden_dim)\n",
        "        self.v = nn.Parameter(torch.rand(rnn_hidden_dim))\n",
        "        \n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, encoder_outputs, apply_softmax=False):\n",
        "        \n",
        "        # Attention\n",
        "        z = torch.tanh(self.fc_attn(encoder_outputs))\n",
        "        z = z.transpose(2,1) # [B*H*T]\n",
        "        v = self.v.repeat(encoder_outputs.size(0),1).unsqueeze(1) #[B*1*H]\n",
        "        z = torch.bmm(v,z).squeeze(1) # [B*T]\n",
        "        attn_scores = F.softmax(z, dim=1)\n",
        "        context = torch.matmul(encoder_outputs.transpose(-2, -1), \n",
        "                               attn_scores.unsqueeze(dim=2)).squeeze()\n",
        "        if len(context.size()) == 1:\n",
        "            context = context.unsqueeze(0)\n",
        "        \n",
        "        # FC layers\n",
        "        z = self.dropout(context)\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return attn_scores, y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVDftS-G7gwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NewsModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_word_embeddings, num_char_embeddings,\n",
        "                 kernels, num_input_channels, num_output_channels, \n",
        "                 rnn_hidden_dim, hidden_dim, output_dim, num_layers, \n",
        "                 bidirectional, dropout_p, word_padding_idx, char_padding_idx):\n",
        "        super(NewsModel, self).__init__()\n",
        "        self.encoder = NewsEncoder(embedding_dim, num_word_embeddings,\n",
        "                                   num_char_embeddings, kernels, \n",
        "                                   num_input_channels, num_output_channels, \n",
        "                                   rnn_hidden_dim, num_layers, bidirectional, \n",
        "                                   word_padding_idx, char_padding_idx)\n",
        "        self.decoder = NewsDecoder(rnn_hidden_dim, hidden_dim, output_dim, \n",
        "                                   dropout_p)\n",
        "        \n",
        "    def forward(self, x_word, x_char, x_lengths, device, apply_softmax=False):\n",
        "        encoder_outputs = self.encoder(x_word, x_char, x_lengths, device)\n",
        "        y_pred = self.decoder(encoder_outputs, apply_softmax)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHPYCPd7Fl3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "D3seBMA7FlcC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnRKWLekFlnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, dataset, model, model_state_file, save_dir, device, \n",
        "                 shuffle, num_epochs, batch_size, learning_rate, \n",
        "                 early_stopping_criteria):\n",
        "        self.dataset = dataset\n",
        "        self.class_weights = dataset.class_weights.to(device)\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.save_dir = save_dir\n",
        "        self.device = device\n",
        "        self.shuffle = shuffle\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_func = nn.CrossEntropyLoss(self.class_weights)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer, mode='min', factor=0.5, patience=1)\n",
        "        self.train_state = {\n",
        "            'done_training': False,\n",
        "            'stop_early': False, \n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'early_stopping_criteria': early_stopping_criteria,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': model_state_file}\n",
        "    \n",
        "    def update_train_state(self):\n",
        "\n",
        "        # Verbose\n",
        "        print (\"[EPOCH]: {0:02d} | [LR]: {1} | [TRAIN LOSS]: {2:.2f} | [TRAIN ACC]: {3:.1f}% | [VAL LOSS]: {4:.2f} | [VAL ACC]: {5:.1f}%\".format(\n",
        "          self.train_state['epoch_index'], self.train_state['learning_rate'], \n",
        "            self.train_state['train_loss'][-1], self.train_state['train_acc'][-1], \n",
        "            self.train_state['val_loss'][-1], self.train_state['val_acc'][-1]))\n",
        "\n",
        "        # Save one model at least\n",
        "        if self.train_state['epoch_index'] == 0:\n",
        "            torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "            self.train_state['stop_early'] = False\n",
        "\n",
        "        # Save model if performance improved\n",
        "        elif self.train_state['epoch_index'] >= 1:\n",
        "            loss_tm1, loss_t = self.train_state['val_loss'][-2:]\n",
        "\n",
        "            # If loss worsened\n",
        "            if loss_t >= self.train_state['early_stopping_best_val']:\n",
        "                # Update step\n",
        "                self.train_state['early_stopping_step'] += 1\n",
        "\n",
        "            # Loss decreased\n",
        "            else:\n",
        "                # Save the best model\n",
        "                if loss_t < self.train_state['early_stopping_best_val']:\n",
        "                    torch.save(self.model.state_dict(), self.train_state['model_filename'])\n",
        "\n",
        "                # Reset early stopping step\n",
        "                self.train_state['early_stopping_step'] = 0\n",
        "\n",
        "            # Stop early ?\n",
        "            self.train_state['stop_early'] = self.train_state['early_stopping_step'] \\\n",
        "              >= self.train_state['early_stopping_criteria']\n",
        "        return self.train_state\n",
        "  \n",
        "    def compute_accuracy(self, y_pred, y_target):\n",
        "        _, y_pred_indices = y_pred.max(dim=1)\n",
        "        n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "        return n_correct / len(y_pred_indices) * 100\n",
        "    \n",
        "    def pad_word_seq(self, seq, length):\n",
        "        vector = np.zeros(length, dtype=np.int64)\n",
        "        vector[:len(seq)] = seq\n",
        "        vector[len(seq):] = self.dataset.vectorizer.title_word_vocab.mask_index\n",
        "        return vector\n",
        "    \n",
        "    def pad_char_seq(self, seq, seq_length, word_length):\n",
        "        vector = np.zeros((seq_length, word_length), dtype=np.int64)\n",
        "        vector.fill(self.dataset.vectorizer.title_char_vocab.mask_index)\n",
        "        for i in range(len(seq)):\n",
        "            char_padding = np.zeros(word_length-len(seq[i]), dtype=np.int64)\n",
        "            vector[i] = np.concatenate((seq[i], char_padding), axis=None)\n",
        "        return vector\n",
        "        \n",
        "    def collate_fn(self, batch):\n",
        "        \n",
        "        # Make a deep copy\n",
        "        batch_copy = copy.deepcopy(batch)\n",
        "        processed_batch = {\"title_word_vector\": [], \"title_char_vector\": [], \n",
        "                           \"title_length\": [], \"category\": []}\n",
        "             \n",
        "        # Max lengths\n",
        "        get_seq_length = lambda sample: len(sample[\"title_word_vector\"])\n",
        "        get_word_length = lambda sample: len(sample[\"title_char_vector\"][0])\n",
        "        max_seq_length = max(map(get_seq_length, batch))\n",
        "        max_word_length = max(map(get_word_length, batch))\n",
        "\n",
        "\n",
        "        # Pad\n",
        "        for i, sample in enumerate(batch_copy):\n",
        "            padded_word_seq = self.pad_word_seq(\n",
        "                sample[\"title_word_vector\"], max_seq_length)\n",
        "            padded_char_seq = self.pad_char_seq(\n",
        "                sample[\"title_char_vector\"], max_seq_length, max_word_length)\n",
        "            processed_batch[\"title_word_vector\"].append(padded_word_seq)\n",
        "            processed_batch[\"title_char_vector\"].append(padded_char_seq)\n",
        "            processed_batch[\"title_length\"].append(sample[\"title_length\"])\n",
        "            processed_batch[\"category\"].append(sample[\"category\"])\n",
        "            \n",
        "        # Convert to appropriate tensor types\n",
        "        processed_batch[\"title_word_vector\"] = torch.LongTensor(\n",
        "            processed_batch[\"title_word_vector\"])\n",
        "        processed_batch[\"title_char_vector\"] = torch.LongTensor(\n",
        "            processed_batch[\"title_char_vector\"])\n",
        "        processed_batch[\"title_length\"] = torch.LongTensor(\n",
        "            processed_batch[\"title_length\"])\n",
        "        processed_batch[\"category\"] = torch.LongTensor(\n",
        "            processed_batch[\"category\"])\n",
        "        \n",
        "        return processed_batch  \n",
        "  \n",
        "    def run_train_loop(self):\n",
        "        for epoch_index in range(self.num_epochs):\n",
        "            self.train_state['epoch_index'] = epoch_index\n",
        "      \n",
        "            # Iterate over train dataset\n",
        "\n",
        "            # initialize batch generator, set loss and acc to 0, set train mode on\n",
        "            self.dataset.set_split('train')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, collate_fn=self.collate_fn, \n",
        "                shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "                # zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                # compute the output\n",
        "                _, y_pred = self.model(x_word=batch_dict['title_word_vector'],\n",
        "                                       x_char=batch_dict['title_char_vector'],\n",
        "                                       x_lengths=batch_dict['title_length'],\n",
        "                                       device=self.device)\n",
        "                \n",
        "                # compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "                loss_t = loss.item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute gradients using loss\n",
        "                loss.backward()\n",
        "\n",
        "                # use optimizer to take a gradient step\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['train_loss'].append(running_loss)\n",
        "            self.train_state['train_acc'].append(running_acc)\n",
        "\n",
        "            # Iterate over val dataset\n",
        "\n",
        "            # initialize batch generator, set loss and acc to 0, set eval mode on\n",
        "            self.dataset.set_split('val')\n",
        "            batch_generator = self.dataset.generate_batches(\n",
        "                batch_size=self.batch_size, collate_fn=self.collate_fn, \n",
        "                shuffle=self.shuffle, device=self.device)\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "                # compute the output\n",
        "                _, y_pred = self.model(x_word=batch_dict['title_word_vector'],\n",
        "                                       x_char=batch_dict['title_char_vector'],\n",
        "                                       x_lengths=batch_dict['title_length'],\n",
        "                                       device=self.device)\n",
        "\n",
        "                # compute the loss\n",
        "                loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "                loss_t = loss.to(\"cpu\").item()\n",
        "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "                # compute the accuracy\n",
        "                acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            self.train_state['val_loss'].append(running_loss)\n",
        "            self.train_state['val_acc'].append(running_acc)\n",
        "\n",
        "            self.train_state = self.update_train_state()\n",
        "            self.scheduler.step(self.train_state['val_loss'][-1])\n",
        "            if self.train_state['stop_early']:\n",
        "                break\n",
        "          \n",
        "    def run_test_loop(self):\n",
        "        # initialize batch generator, set loss and acc to 0, set eval mode on\n",
        "        self.dataset.set_split('test')\n",
        "        batch_generator = self.dataset.generate_batches(\n",
        "            batch_size=self.batch_size, collate_fn=self.collate_fn, \n",
        "            shuffle=self.shuffle, device=self.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            _, y_pred = self.model(x_word=batch_dict['title_word_vector'],\n",
        "                                   x_char=batch_dict['title_char_vector'],\n",
        "                                   x_lengths=batch_dict['title_length'],\n",
        "                                   device=self.device)\n",
        "\n",
        "            # compute the loss\n",
        "            loss = self.loss_func(y_pred, batch_dict['category'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = self.compute_accuracy(y_pred, batch_dict['category'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "        self.train_state['test_loss'] = running_loss\n",
        "        self.train_state['test_acc'] = running_acc\n",
        "    \n",
        "    def plot_performance(self):\n",
        "        # Figure size\n",
        "        plt.figure(figsize=(15,5))\n",
        "\n",
        "        # Plot Loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(trainer.train_state[\"train_loss\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_loss\"], label=\"val\")\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        # Plot Accuracy\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(trainer.train_state[\"train_acc\"], label=\"train\")\n",
        "        plt.plot(trainer.train_state[\"val_acc\"], label=\"val\")\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "        # Save figure\n",
        "        plt.savefig(os.path.join(self.save_dir, \"performance.png\"))\n",
        "\n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    def save_train_state(self):\n",
        "        self.train_state[\"done_training\"] = True\n",
        "        with open(os.path.join(self.save_dir, \"train_state.json\"), \"w\") as fp:\n",
        "            json.dump(self.train_state, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICkiOaGtFlk-",
        "colab_type": "code",
        "outputId": "93b4b2b0-c290-4994-db29-bbb126c8bb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "dataset = NewsDataset.load_dataset_and_make_vectorizer(df=split_df,\n",
        "                                                       cutoff=args.cutoff)\n",
        "dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.vectorizer\n",
        "model = NewsModel(embedding_dim=args.embedding_dim, \n",
        "                  num_word_embeddings=len(vectorizer.title_word_vocab), \n",
        "                  num_char_embeddings=len(vectorizer.title_char_vocab),\n",
        "                  kernels=args.kernels,\n",
        "                  num_input_channels=args.embedding_dim,\n",
        "                  num_output_channels=args.num_filters,\n",
        "                  rnn_hidden_dim=args.rnn_hidden_dim,\n",
        "                  hidden_dim=args.hidden_dim,\n",
        "                  output_dim=len(vectorizer.category_vocab),\n",
        "                  num_layers=args.num_layers,\n",
        "                  bidirectional=args.bidirectional,\n",
        "                  dropout_p=args.dropout_p, \n",
        "                  word_padding_idx=vectorizer.title_word_vocab.mask_index,\n",
        "                  char_padding_idx=vectorizer.title_char_vocab.mask_index)\n",
        "print (model.named_modules)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_modules of NewsModel(\n",
            "  (encoder): NewsEncoder(\n",
            "    (word_embeddings): Embedding(3406, 100, padding_idx=0)\n",
            "    (char_embeddings): Embedding(35, 100, padding_idx=0)\n",
            "    (conv): ModuleList(\n",
            "      (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
            "      (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
            "    )\n",
            "    (gru): GRU(300, 128, batch_first=True)\n",
            "  )\n",
            "  (decoder): NewsDecoder(\n",
            "    (fc_attn): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (dropout): Dropout(p=0.25)\n",
            "    (fc1): Linear(in_features=128, out_features=200, bias=True)\n",
            "    (fc2): Linear(in_features=200, out_features=4, bias=True)\n",
            "  )\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tuaRZ4DiFlh1",
        "colab_type": "code",
        "outputId": "d013194a-3608-4acd-9313-c8c3ab4d8a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "trainer = Trainer(dataset=dataset, model=model, \n",
        "                  model_state_file=args.model_state_file, \n",
        "                  save_dir=args.save_dir, device=args.device,\n",
        "                  shuffle=args.shuffle, num_epochs=args.num_epochs, \n",
        "                  batch_size=args.batch_size, learning_rate=args.learning_rate, \n",
        "                  early_stopping_criteria=args.early_stopping_criteria)\n",
        "trainer.run_train_loop()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[EPOCH]: 00 | [LR]: 0.001 | [TRAIN LOSS]: 0.77 | [TRAIN ACC]: 69.6% | [VAL LOSS]: 0.56 | [VAL ACC]: 79.9%\n",
            "[EPOCH]: 01 | [LR]: 0.001 | [TRAIN LOSS]: 0.50 | [TRAIN ACC]: 81.9% | [VAL LOSS]: 0.50 | [VAL ACC]: 81.5%\n",
            "[EPOCH]: 02 | [LR]: 0.001 | [TRAIN LOSS]: 0.44 | [TRAIN ACC]: 84.4% | [VAL LOSS]: 0.45 | [VAL ACC]: 83.9%\n",
            "[EPOCH]: 03 | [LR]: 0.001 | [TRAIN LOSS]: 0.39 | [TRAIN ACC]: 86.0% | [VAL LOSS]: 0.48 | [VAL ACC]: 82.8%\n",
            "[EPOCH]: 04 | [LR]: 0.001 | [TRAIN LOSS]: 0.36 | [TRAIN ACC]: 87.2% | [VAL LOSS]: 0.44 | [VAL ACC]: 84.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzRJIz88Flfe",
        "colab_type": "code",
        "outputId": "0ad7195f-54a0-4cb5-ed87-eee89ec1fcab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot performance\n",
        "trainer.plot_performance()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAE/CAYAAADVKysfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm4iIiIiIiIf9f8rUK6BcwRjjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4EmFhiX-FMaV",
        "colab_type": "code",
        "outputId": "13ef8783-ec18-4391-b926-94507083ee45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# Test performance\n",
        "trainer.run_test_loop()\n",
        "print(\"Test loss: {0:.2f}\".format(trainer.train_state['test_loss']))\n",
        "print(\"Test Accuracy: {0:.1f}%\".format(trainer.train_state['test_acc']))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.43\n",
            "Test Accuracy: 84.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zVU1zakYFMVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save all results\n",
        "trainer.save_train_state()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLoKfjSpFw7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ]
    },
    {
      "metadata": {
        "id": "51_PWM3xgXHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Inference(object):\n",
        "    def __init__(self, model, vectorizer, device=\"cpu\"):\n",
        "        self.model = model.to(device)\n",
        "        self.vectorizer = vectorizer\n",
        "        self.device = device\n",
        "  \n",
        "    def predict_category(self, dataset):\n",
        "        # Batch generator\n",
        "        batch_generator = dataset.generate_batches(\n",
        "            batch_size=len(dataset), shuffle=False, device=self.device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Predict\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # compute the output\n",
        "            attn_scores, y_pred =  self.model(\n",
        "                x_word=batch_dict['title_word_vector'],\n",
        "                x_char=batch_dict['title_char_vector'],\n",
        "                x_lengths=batch_dict['title_length'],\n",
        "                device=self.device,\n",
        "                apply_softmax=True)\n",
        "\n",
        "            # Top k nationalities\n",
        "            y_prob, indices = torch.topk(y_pred, k=len(self.vectorizer.category_vocab))\n",
        "            probabilities = y_prob.detach().to('cpu').numpy()[0]\n",
        "            indices = indices.detach().to('cpu').numpy()[0]\n",
        "\n",
        "            results = []\n",
        "            for probability, index in zip(probabilities, indices):\n",
        "                category = self.vectorizer.category_vocab.lookup_index(index)\n",
        "                results.append({'category': category, \n",
        "                                'probability': probability})\n",
        "\n",
        "        return attn_scores, results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h8UoSJPggXC9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load vectorizer\n",
        "with open(args.vectorizer_file) as fp:\n",
        "    vectorizer = NewsVectorizer.from_serializable(json.load(fp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woxuiUA2gXAX",
        "colab_type": "code",
        "outputId": "872463fe-0517-4f34-927c-fe6135092e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = NewsModel(embedding_dim=args.embedding_dim, \n",
        "                  num_word_embeddings=len(vectorizer.title_word_vocab), \n",
        "                  num_char_embeddings=len(vectorizer.title_char_vocab),\n",
        "                  kernels=args.kernels,\n",
        "                  num_input_channels=args.embedding_dim,\n",
        "                  num_output_channels=args.num_filters,\n",
        "                  rnn_hidden_dim=args.rnn_hidden_dim,\n",
        "                  hidden_dim=args.hidden_dim,\n",
        "                  output_dim=len(vectorizer.category_vocab),\n",
        "                  num_layers=args.num_layers,\n",
        "                  bidirectional=args.bidirectional,\n",
        "                  dropout_p=args.dropout_p, \n",
        "                  word_padding_idx=vectorizer.title_word_vocab.mask_index,\n",
        "                  char_padding_idx=vectorizer.title_char_vocab.mask_index)\n",
        "model.load_state_dict(torch.load(args.model_state_file))\n",
        "print (model.named_modules)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_modules of NewsModel(\n",
            "  (encoder): NewsEncoder(\n",
            "    (word_embeddings): Embedding(3406, 100, padding_idx=0)\n",
            "    (char_embeddings): Embedding(35, 100, padding_idx=0)\n",
            "    (conv): ModuleList(\n",
            "      (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
            "      (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
            "    )\n",
            "    (gru): GRU(300, 128, batch_first=True)\n",
            "  )\n",
            "  (decoder): NewsDecoder(\n",
            "    (fc_attn): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (dropout): Dropout(p=0.25)\n",
            "    (fc1): Linear(in_features=128, out_features=200, bias=True)\n",
            "    (fc2): Linear(in_features=200, out_features=4, bias=True)\n",
            "  )\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yfc666nngW9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "inference = Inference(model=model, vectorizer=vectorizer, device=\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1soPBCApgW7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InferenceDataset(Dataset):\n",
        "    def __init__(self, df, vectorizer):\n",
        "        self.df = df\n",
        "        self.vectorizer = vectorizer\n",
        "        self.target_size = len(self.df)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Dataset(size={1})>\".format(self.target_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        title_word_vector, title_char_vector, title_length = \\\n",
        "            self.vectorizer.vectorize(row.title)\n",
        "        return {'title_word_vector': title_word_vector, \n",
        "                'title_char_vector': title_char_vector, \n",
        "                'title_length': title_length}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    def generate_batches(self, batch_size, shuffle=True, drop_last=False, device=\"cpu\"):\n",
        "        dataloader = DataLoader(dataset=self, batch_size=batch_size, \n",
        "                                shuffle=shuffle, drop_last=drop_last)\n",
        "        for data_dict in dataloader:\n",
        "            out_data_dict = {}\n",
        "            for name, tensor in data_dict.items():\n",
        "                out_data_dict[name] = data_dict[name].to(device)\n",
        "            yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tU70BuYvgW4Q",
        "colab_type": "code",
        "outputId": "0de9b0f0-b941-46f3-803f-d2db47ee37da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "title = input(\"Enter a title to classify: \")\n",
        "infer_df = pd.DataFrame([title], columns=['title'])\n",
        "infer_df.title = infer_df.title.apply(preprocess_text)\n",
        "infer_dataset = InferenceDataset(infer_df, vectorizer)\n",
        "attn_scores, results = inference.predict_category(dataset=infer_dataset)\n",
        "results"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a title to classify: Leader of armed militia in New Mexico allegedly beaten in jail \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'category': 'World', 'probability': 0.9965551},\n",
              " {'category': 'Sci/Tech', 'probability': 0.0023580808},\n",
              " {'category': 'Business', 'probability': 0.00094656425},\n",
              " {'category': 'Sports', 'probability': 0.00014026604}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "R3jrZ6ZkxN4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Interpretability"
      ]
    },
    {
      "metadata": {
        "id": "qrAieHoHxOt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can inspect the probability vector that is generated at each time step to visualize the importance of each of the previous hidden states towards a particular time step's prediction. "
      ]
    },
    {
      "metadata": {
        "id": "k6uZY4J8vYgw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQwfUfwzjE_F",
        "colab_type": "code",
        "outputId": "7cdf28b1-daec-46eb-dd64-7a4788a58eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "attn_matrix = attn_scores.detach().numpy()\n",
        "ax = sns.heatmap(attn_matrix, linewidths=2, square=True)\n",
        "tokens = [\"<BEGIN>\"]+preprocess_text(title).split(\" \")+[\"<END>\"]\n",
        "ax.set_xticklabels(tokens, rotation=45)\n",
        "ax.set_xlabel(\"Token\")\n",
        "ax.set_ylabel(\"Importance\\n\")\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADxCAYAAAAwXvePAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu8pWP5x/HPd2aMU5JIfqEcUySF\nJCXllJzGuXEmxyR0Yvr9pFARoZRkkkqREJqiJKV0NKPkVDLJYRQS5RRjZl+/P657jWW3Z+9nrb3W\n3ns9833Pa71m77XXetazTtdzP9d93fetiMDMzOpl3GjvgJmZdZ6Du5lZDTm4m5nVkIO7mVkNObib\nmdWQg7uZWQ05uJuZ1ZCDu5lZDTm4m5nV0ITR3gEzs17z7MN3VR7av9Ayq6ib+zI/brmbmdWQW+5m\nZq3qmzvaezAkB3czs1bNnTPaezAkB3czsxZF9I32LgzJwd3MrFV9Du5mZvXjlruZWQ25Q9XMrIbc\ncjczq59wtYyZWQ25Q9XMrIacljEzqyF3qJqZ1ZBb7mZmNeQOVTOzGnKHqplZ/UQ4525mVj/OuZuZ\n1ZDTMmZmNeSWu5lZDc19drT3YEgO7mZmrXJaxsyshpyWMTOrIbfczcxqyMHdzKx+wh2qZmY15Jy7\nmVkNOS1jZlZDbrmbmdWQW+5mZjXklruZWQ3N8WIdZmb145a7mVkNOeduZlZDbrmbmdWQW+5mZjXk\nlruZWQ25WsbMrIYiRnsPhuTgbmbWqh7IuY8b7R0wM+s5fX3VLxVI2krSHZJmSpoyyO12lhSS1h9q\nm265m5m1qoMdqpLGA2cBWwCzgOmSpkXE7f1utwRwJPDbKtt1y93MrFVz51a/DG0DYGZE3BURs4GL\ngEkD3O5E4NPA01U26uBuZtaqFtIykg6WNKPpcnC/rS0P3Nf0+6xy3TyS1gVWjIgrq+6i0zJmZq1q\noUM1IqYCU9t9KEnjgNOB/Vq5n4O7mVmrOjuI6X5gxabfVyjXNSwBvAa4ThLAcsA0SdtHxIz5bdTB\n3cysRdHX0Tr36cDqklYmg/pkYI95jxXxb2CZxu+SrgM+NFhgBwd3M7PWdbDOPSLmSDocuBoYD5wX\nEbdJOgGYERHT2tmug7uZWauqVcFUFhFXAVf1u+64+dz2bVW26eBuZtaqHhih6uBuZtYqB3czsxry\nxGFmZjXklruZWQ11thSyKxzczcxa1eFqmW5wcDcza1E4LWNmVkNOy5iZ1ZAXyDYzqyG33M3MamiO\nO1TNzOrHaRkzsxpyWsbMrH5cCmlmVkduuZuZ1ZCDu5lZDXn6ATOz+unwGqpd4eBuZtYqB3czsxpy\ntYyZWQ255W5mVkMO7mZm9RNznZYxM6sft9zNzOrHpZBmZnXk4G5mVkNjP+Xu4G5m1qqYM/aju4O7\nmVmrxn5sd3A3M2uVO1TNzOrILXczs/pxy93MrI7ccjczq5+YM9p7MLRxVW8o6RWSNi8/Lyppie7t\nlpnZ2BV91S9VSNpK0h2SZkqaMsDfD5V0i6SbJP1C0ppDbbNScJd0EHApcE65agXgimq7bWZWM30t\nXIYgaTxwFvBOYE1g9wGC94URsXZEvA44BTh9qO1Wbbm/F3gz8BhARNwJLFvxvmZmtdLhlvsGwMyI\nuCsiZgMXAZOe93gRjzX9ujgwZI9u1Zz7MxExWxIAkiZU2biZWR1VTbdUtDxwX9Pvs4A39r+RpPcC\nHwAmApsOtdGqLfefSfpfYFFJWwCXAN+reF8zs1qJuap8kXSwpBlNl4PbesyIsyJiVeAY4Nihbl+1\n5T4FOAC4BTgEuAo4t50dNDPrda203CNiKjB1kJvcD6zY9PsK5br5uQg4e6jHrRrcFwXOi4gvw7wO\ngEWBpyre38ysNqJPndzcdGB1SSuTQX0ysEfzDSStXvo6AbYB7mQIVdMy15LBvGFR4McV72tmViud\n7FCNiDnA4cDVwB+BiyPiNkknSNq+3OxwSbdJuonMu+871HarttwXiYgnmnbmCUmLVbyvmVmtRHS0\n5U5EXEWmu5uvO67p5yNb3WbVlvuTktZt/CJpPeA/rT6YmVkddHoQUzdUbbkfBVwi6W+AgOWAd3Vt\nr8zMxrC+uZ1tuXdDpeAeEdMlvQpYo1x1R0Q8273dMjMbuzrcodoVrUwc9gZgpXKfdSUREed3Za/M\nzMaw2gR3Sd8AVgVuAuaWqwNwcDezBU70wPj8qi339YE1I3rhKZmZdVdtWu7ArWQn6t+7uC9mZj2h\n06WQ3VA1uC8D3C7pBuCZxpURsf387zLifFZhZlUNKzrPrUu1DPDxbu5Ep0yYuHxHtjNn9nPTOozV\nbXZ7Hz+w0uRhb+/0uy+a9/OXVtxr2NsDOPS+b877+diV9hjkltV94u4L5/3cC+9NL+zjsw/f1ZFt\nLrTMKvN+XnyxlYa9vSefunvY24Aatdwj4mfd3hEzs17RCzn3qisxbShpuqQnJM2WNFfSY0Pf08ys\nfiKqX0ZL1bTMF8iZyi4hK2f2AV7ZrZ0yMxvLatNyB4iImcD4iJgbEV8FturebpmZjV1z+8ZVvoyW\nqi33pyRNBG6SdApZEjl6e21mNop6YcRP1QC9d7nt4cCT5KohO3Vrp8zMxrK+UOXLaKnact8hIj4H\nPA0cDyDpSOBzndiJMinZJHKhWMjVSKZFxB87sX0zs07qhVLIqi33gVb92K8TOyDpGHJNQAE3lIuA\nb0ma0onHMDPrpJ6vlpG0O7mW3yqSpjX9aQngkQ7twwHAWv2nEJZ0OnAbcPIg+3cwcDDAOeec06Hd\nMTMb3GimW6oaKi3zK7LzdBngtKbrHwdu7tA+9AEvA+7pd/3/lL/NV79VxeOww4/v0C6Zmc3faFbB\nVDVocI+IeyTNAp7u4ijVo4BrJd0J3FeuezmwGtmBa2Y2pvRAsczQHaoRMVdSn6QlI+Lfnd6BiPih\npFcCG/D8DtXpETF3/vc0MxsddUjLNDwB3CLpGrIUEoCIOKITOxERfcBvOrEtM7Nu64VqmarB/bJy\nMTNb4A3aGThGVJ0V8utlhGpjPhkvkG1mC6wY3nTwI6LqGqpvA74O3E3WoK8oad+I+Hn3ds3MbGya\nU6O0zGnAlhFxB0DpAP0WsF63dszMbKzqhZa7qqx5LenmiHjtUNeNsl6oTjKzsWFY0fmal76rcrzZ\n4sFvj8qRoGol/gxJ50p6W7l8GZjRzR1rg6pcJB1S9bajtc1e2McF9Xn3wj4uqM+7xe0NS6DKl9FS\nNbi/B7gdOKJcbi/X9aKDe2CbvbCP3dim93HsbnNB3ccB9bVwGS1Vq2WekfQF4Fpyf++IiNld3TMz\nszFq7ii2yKuqWi2zDfAl4C/kKc3Kkg6JiB90c+fMzMaiHlhlr6VqmbeXpfaQtCpwJdCLwX3q0DcZ\n9W32wj52Y5vex7G7zQV1HwfU1wMt96rVMtMj4g1Nvwu4ofk6M7MFxRXL7VG5WmaHBy4clSNB1Zb7\nDElXAReTJYe7AtMl7QQQEZ6awMwWGLWZfgBYBHgQ2KT8/g9gUWA7Mtg7uJvZAqNPYz8tU7VaZv9u\n74glSRsB/2yMBh6Bx1ssIp4aiccya5C0EvCaiPj+KO9KWzo9F7mkrcg1qccD50bEyf3+/gHgQGAO\n2bh+d0TcM9g2K9W5S1pZ0umSLpM0rXFp61ksQErfRCu33xD4GvCspIW7slPPf7w1gA+UBcrNRtJr\ngC9J2mG0d6Qdfap+GYqk8cBZwDuBNYHdJa3Z72a/B9YvswJcCpwy1HarDmK6gpw07PNk5UzjskBo\nNUg37hOlt1rSXpI2GOL248jVpy4DVgIOkVQ1bdauZYHlgB0krTbcjTW/TlUPTu28tu2S9PryOndr\n+yPyXCStU+Z3opXnM9BtB9vnbjwfSa+UtGppsR8GnNjou+slfajypYINgJkRcVcZP3QRMKn5BhHx\n06Yz7N8AKwy10arB4+mIOLPibWujEaCjSklRP02BfRLwbmDyEI/TJ+ly8qB5ELBGRMxpc9cH1fS8\nrpe0PvAmYDFJ50XE3cPZZvn5MGB1SY8An42IxyvcZ2tyDMWvI6JTi6/PexxgcXKsxreAz3Zy+43H\naHouGwAvBH4HPNaF9/Hd5FKUO5aFbipp3FbSLmX/bo6IGZLG9d9OF9+bNwD3SZoVEdPKVOLHS+p6\nYcZAz7NdHZ7IanmeW2IUYBbwxkFufwAVytCrHvU/J+ljkt4kad3GpeJ9e0pzayUiQtILJb1G0qkl\nULeyrTeSX8TrI+Kh+dxmXNPB40XAj4CHgN3aewZDa/rSHgHsSH6wNgb2bLcF3y+wTwa+QK6Pe1qj\nldmgNK7pPvuTp5nHAB+T9Na2ntj8rR0RTwB7AttL2rzD229+/h8in/sUMoe6v6RFh7Ptctre7Bjg\n8XJgbqmFLWlf4CRgFeAnkjYrDYtxjW11872JiAvI6UsekLRORFwKfJwM8B1P0fT7PvdJepGkjSRd\nLGmfdrfbSlpG0sGSZjRd2p4mQdJewPrAqUPdtmrLfW1gb2BTnqsCivJ7rTR9qJcH/of8YP8G2Af4\n4WD3bW7tFI+Q6azXS3pjRPy2/+2aWlOHkHnIh4CPkkFx0YjoSvpL0kuArYA9I+I+SW8nDyh7SvpG\nRNxVcTubAP+IiNslvRjYsGxnV7LluiRwsqQpEfHncrfxjdascvTzTuRnbALwMWC78hJdP8znOJ7M\nYd4k6Txy4N1ngddK+i3wRDtnZYM83svJ1/QtETFb0rvI1+NVZM601e2tBKwUEddJeguZQvtrRNwo\n6WHydH5G1eegXJdhE2DbiLhD0q3A5ZJ2iIiflAA/rtvvTUQ8LOl04IeStoyI70gK4AxJ4yPiO+1u\ne4DHanyfVyVTGSeTrd43Ape3u91Wmv8RMZXBB1jdD6zY9PsK5brnKY2S/wM2iYhnhnrcqi33XYFV\nImKTiHh7udQqsDe3riS9BziHnBztK8BVwN+BmYPcv/k0dmdlHvHFwLHAreSXYn147gPXdN+dyQnZ\nvgJMJE+5zwP2k3RSh57f81p3EfEP4BnKGUJE/JQMxnuTOfiFKm76f8hW5IvLKfuh5GnmThGxBXnm\nsimwm6SJ5aByWWkhTiBbIZsAG0Su7vW5sl+7KyuHhiMi4hbgRLLCYA/yPd0YWHW4gX2AFvOT5NlX\no3/lEmAp8uyoHW8ELpC0MVmgsQlwkrJy4gbgMEmrD7V/5bUeD2wDrAO8SdIiEXEROdnWj8tBemk6\n/N6UbTX2Yw2VM/6IOBH4DHCdpNeUlMzRZONmWJqfd/n/KPK7tSNwOtmv9W/gxnYfY66qXyqYTqYx\nV1amqSYDzytYkfR6MiZtP78sQH9Vg/ut5Ie2lpRpg49IWrUEtUXII+Qx5TRyezJ3PGjpUdnWe4AP\nAgsDvyY7Ry8gz3T20sDprDWAr0bETeW+T5FBYXdgY0nLDPP5NR94Npb01hJkLwBeVA4ukGMZZgDf\njCGWUWx8cUqAeBa4U9KGpdNnNjBB0srA24CrgfMjYnY5qEwGNgdeEBHHkx31UyS9tvz988ADDHIw\nHWrflOmDmyWtBfyxPLd9gZ+RwfdLzYGnncdoek0PkjSZfN8uIt+zdeK5hd+l1jo+V5X08oj4Npne\n+SLQFxHvA/Yjl7tcB3gF8Ppyn/H9ttF8FvkKYKGI+HDZv3WBN0iaUN6/XYEHuvHeRFHOAq4gCwVu\nlLR8OSs9EfidpLUj4pLIfqDhduQu3O//+8hGx0cj4hIyyJ/VdCbZsk7OClnOlA4nvyd/BC6OiNsk\nnSBp+3KzU4EXAJdIukkVqhWrTj9wHfBa8ggz73QgIraf3316iTIlMYlMo5wbEX9r+tsSZJnSGRHx\nX6fW5Ut4b/l5ZbJlsB/5JdmNXMFqbjkt3BM4u3xJmrexA7A/8JGIuL1c9zPylPjRTnUCSfowsDVw\nD3kA+yZ58Gl0mK0E7NzYh0G2syzwyoj4hTKHewUZOA8pz2M6mUfdmEwl7BwRf+y3jR3I3PRawGPA\nR8iVvT4ZEb9TBzq/lKmutYF7gb3IA+gZkl4NPNl439rctkrQOpD8Yu4YEX9VdqZuDWwB3ESmabYb\n6jXtt+1jgE8Aq0XEPZL2Iw/6x0TEVcpKpHHlul3IErkBO20lvQ/YgQxwT5V9/SQZ+L4P/Lz/fTvx\n3khaETguIg6S9DrgwvJarEt+7m4B9iiv2YeAP0TENVVfo0Ee9x3kwepFZCrpkxExvenvE8lGzedj\nGMuEnrPCXpXP+g6Z9c1RGfFUNbhvMtD1EfGzju/RCJL0gsiOtsbgoZ2Bx8mWa2OStC8AS0bE3gPc\n/6XA8cCdEXFaafUfT35x1gB2jYj/lC/Yd4AHI+K/xj9IehHwITLAXkeO/j0OeGf/A8Ewnus6wPER\nsYOkE4F1I2IbSS8o+/sashzrv3J9/bazcLn9NOA/wDLADhFxv6T3Au8DJkfETcqUwX8iYtZ8trUV\n2RJcnwwiJwIrk6mc2e2kTSQdTpaULka+hkuSAf6D5frJEXFtq9tt2v4awN8j4rFy4L8AOCkift0I\nepKWIw+UryDnYPprxW03nw2cTgblt0bELGXn34eBD0bEj5rucxlw7EAHD2UBwJFkS/U44LURsYWk\nRYBPkQNiPhYR/xngvsN+b8pn7l9kqmVp8jN2Apnq+SqZdtq08fr0O9tomaQtgTPJ10lkX8dHgL0j\n4vvljOBT5EFz13YfB+BLK1YP7ofeNzrBveoI1Z4O4gMpH96PSrqCDFS/Jz+Ie5Lpk0aA/znwy3Kf\n/h++x8hO1s0kvScizi6t2p0jYqlyn93IztgrBgrsABHxL0lfJFvqHwaeAA4YTmAfYF+fBO6RdCYZ\n5Bp54LcCP6ryHpcv6zoRcb6kqeSX/9wS2CdExFklPXCNpG0i4obBthcRP5R0JJm6eFNEHCtp6ajQ\nWTSf/XsPGRAPJvOq/xsRRwB3SLqT7Kj+UzvbLttfihxocr6kiRHxuKTHybQU5PdpNvAyYHpE/KaV\n7TcF9i3JA+fjwC8lbVJe8z7gHEmHRsTVkl5LBrDHyv0mxvPXWXicDGb7kQe4rcv1q5P57aUGCuxl\nX9p+bxqfvYj4g6RrgKUjYl1JOwJXlwbPpWXf56V7hxnYtyH7BLaJ7CxWZKnlw8A3lVVBNyrnyHqk\n3Kfts8Oen1umfHAHesFFvhcv7MpejYzFyfrulchT3N3JVkWQp697SDob+G657r8+fOVDujTZcbqv\npEcj4kBlx8jl5MFiLXKocHMd638pqaAvKKs6FBFPtvvE+rUAlyGrQmZKWhJYFXhX5AIsB5IdjNPJ\nDsfBtjme7IS6uqSYHgY2IwPdYxHxyfI8zpR0H+ULNJSSZpgIXCtp/Yj45zCe77JkOmxfstrgg6WV\nukgJNHvEMBaZiYhHJZ1DHhwPkDSF7I86T9KbIuJJSbuTr+kk4NE2nstqwJfJNNJpwPuBXymrrb6p\n7OhsDGb5G/C2iHionP2tL+kW8sB9D9k5/3Xgd1EKICS9m+wHOXSoxkO7703z96ScKXxf0o/JVM+r\nJZ1A5vUPigFSnW1agyzv/Hv5faKk2RFxnqSXAUdKOoBsxP2n7FvbMbrT0w90w6DBPSKWGKkdGSmS\n3kzO3fKdcrS/mGyd/Io8Bd2OPF19ffn/5Pl9CMqp8vvJL/M2wKalNbCZskNvUXLVqrur7l90YJ6X\npsB+NBmAX6gcuHIhmXo6TdK9wLbAbkN9yZXTE+xMDgB6FDibbJmeVFpj0yQ9RfbHTCJbT5UH7kTE\nFZJ+PIyW2+qS7iK/3JeSHX6TImKOpIOAKEF50E7iimaTDYMJwIci4hPKEtAfS/oz2Ro9KCJaDuzF\n48B1kR2L4yLioyUVdKOk9SLiazDvgPZw0/2eBTYi0y/LAltElrh+EjhU2a+0PuXMtOrnbDjvTaNl\nHBHblsbOmeQZw4bAZ6IpF96uclD9dUScLmlxYKakt0TEn8uB/Wmyz2WVyCKBTnwGarVYR51sTbbK\n3xERP5B0KJmW2Tays+0CsjZ6V+DyQQJ7owPyjPJFvIWsqjlQ0hIRcc6IPJt++9QU2JclSxD3IvOu\n3yWf08lkrnMx4Msl9TTYNscBS5DljbuQozw/Ts5JczR5Krwt2Um3CHB0K4G9IUrfR6uUOfYjyffw\nr2VfLiqBfT+yA3HScFppTY+1DZmz37u0aHeU9DEyYK1GVjM8PNRZWr9tNjpmFycPHP8C1pJ0WER8\nsdzscrL2eTXKSMam97mRAnlS0rVkKeu1wPiSKjtV0jNkym8isHv069weSrvvTZTBUSXA76jsHzgg\nskQWZU37cBvBUyStERGviogTy/fyeklvjecm31sMeKyc9cwdTvqnoefTMnUiadmIeCgi/k/SbOBS\nSbtGxAX5eeBKSbtEdlY9RHZsNt//eTns8oWcBbxb0nUR8RdJF5PVImvrubrvkXp+zYF9HzIg/7m0\nyo+VNIesu94/svytyjZfBWwWmUufCLyLDJZfJEuzppAdqOeSQWVizCeH2w3KMrHXklUYW5JD6qcB\nx0h6DXn2tUtE3Nmhh7yP7LsgIn5eDnzbkemTT7bzOOVztA35Ot5L1l7vCvxW2WH/IDkb4F6RA8Wa\n3+fmnxcjS2/fRo6ZOJw807qRLEP9V//P8EjoF+B3knSFpFMi4ugOBHYiYpKk70i6MSLWi4gTlH0T\n1ys79DckX4vd2ml0zE8vBPeuTaI0lig7T6dKOqJ8wI8nW0OXlqP+BWQn3A+Vo/j637/5S7SVpN2V\nFRGXkKPdpig7t7YkUxMnjmRgh+e15LYjKwTWAtZTlgMSER8Hfkx2yE0sLZyhLAJcXIL8LWSFw3Lk\nhE/3k8PY30IGdkY4sC9P5nAnRMRfyEFf95EdpheS/SdbRwsliIM81ublLGAZMgW0CkBEXEd+jp4i\np2ptZ9sbkxVWHyAD+eGR1SObkH09q5EVLbeXx3xeA6Ns41Dy+X8IeAlZRrkQsIukz5P9JC8a6cDe\ntJ/zpjcgD74v1TAmxZO0qaStS7qKiNgZ+JOkP5TfP0GmgB4FziAD+7A/B82ihctoqVQK2cskbUt+\n2I8ia8b/0PS348hW0s4lR7cLcEvMZy51ZUnjnsBPyNzyEeQHaDMyJTMHOKr5Mbqt34GnMUXEaRFx\nq7JSZ1Pg9400kaRl+uVqB9rmvCoCZUfdCWTK4OPkAJr9yOA+FXgpOTnW3wbcWBcpRwF/AfhARFxU\nAsh+ZDXIpyPiX21ut/k1XZKcyG1L8sDRGGzyUzJ/ez5ZM/90m4/1TjIvvBhZzTM5Iu5WDvK5v+l2\nA7a6S2Dfgyz1PJU8szgT+AVZJLAOmX67uZ3967TSeHqo3WCrLD/9MVkvfyv5PH9E1uxfACwfEZuU\n2x4C/DIibu3Arj/PKa+oXgp59D1juBSyV0l6BRmY3hMRv266/kCyQ/CEkq74iaS3RU5iNL9tbULm\nLd9KtvIXIVtKZ5a85tlkY6rtKpdW9QtCryNL8LYlR2HeSgYhgEmSno2I84AhKx6aAvv2ZOC5k2yZ\nHkvm1r9KphH2J/scRqtFeFnJJ5+knFXwIklfAxaP+cxEOZR+r+lywFMR8RlyqDzKaSp+R9b6v44c\nA9FOhc8KZMNgIlkdcy/ZCfq4pM3I6RqmROmYnU9gfwl5NrEdWW7bB3yPbHRMiIhz1cGZEDuhnO20\npaTabic/hzuS1UJLkt/Jj5BpqM9JuiEiNogu9nv1fLVMDSxODhxqHmByEplWuFLS6RHxqZKhmO+U\np5C1/pL2ID9UkyJiVUmfAb4iaa+I+MnIPa15+zQvVUSeur9J0gNkjn1m5AjSa8gzil8132cg/QLb\nZLKz9Mtkq/UHZNpgCvBpcgKuB0crsDdExJUlxzpV0pxygG4rsJftNc/uuAmwtKQryeknniRTmeMi\nouVpgxuvr3K8wOFkq/Jrygqud5Dle9uT6a6jo1/FzQCfyX9I+hR5prJNRGyq7EjfD9hJ0vUR8Vjr\nr8LYoxx5+mmyD+Ua5ZiD1wP3RsTnlQvdvIg8q15T0spRcfBYO/pGNeFSTS2Du6RVImc1fIpS+lQC\n+zJk2mVJSf9L1irfGBGf6nf/5iD35nL1nyLi78pOrlvKdb8j0xQtVR90knIK0A+TOVsi4uvKUaRf\nlvTeyNn+Lh8qCPd7zi8n04UbRXYU30y2li4lT/vfD5ww2oG9IbLq6d3AXzqxPeXw+80jYitJ55Ml\nhI3+hGuBVdVG5UUJ7NuR71eQ+fsgX1uRaa6FyRLLHwwQzOfNZUPOIjiHXLnrGWA5Zaf3m8mZSKfU\nKLBvRQ7GOipyvMaiEXFxOWvbXDky+lsR8YikX5IH3393c5/GzKnQIGoX3MsH4ShJB5Tc5YslXRAR\ne0ZONXpxuelfeW6Y+pPlvs9bnEM5F8s7ycnzFy85+huBd5btrEZOMfB3RsgAudefkTnWncjAQ0RM\nVdb4nqqcKnbQfHC/wH4E2a+wBHC6pPvLFwmyKuSL5LwcYyKwN8Qw5iUZIHXxJHlG9lGyT2Hb0jhY\nlTImItqovCit6g+RA4huL+nBDYFnIyf1QtLijdTefFIxR5D9OyeQ70dElgDeSH4WXkjO2dKRaStG\nm3Im1bOB90VOfbwi8EVJH42I75aD7JvJEuSvjtTzHlMf/vmoVXBXDts+mexga3RGbUWOsLuQXMFk\nTmntHgHs0y9HPr78fTw5XPst5VT3U+RivrcpB6wcS46w+2hkpcaI6BeEDyfn6riVrN2/WtLdEXEq\nzBspen5UqGBp2uYOZCt1b7L8bm1gQ0m/KAF+DnBTjHAlULfFc30MO5Bne28mOyJFGZBVguo7yAnC\n2h3lOptM6yxP5o7PI0s531de28t4bvQpZZ8a6cTGe78i2eA4ghxVfIqyXvwAZQXR09FGH8AY9gxZ\nmjxOOeHbV8hW+k0AkYMRRY7d6MrKZQNxy30EKXvhp5I5uRnKztTjyKl7NyVLsC4iO7BeTA6m+FPT\n/ZcBZkhat5zezQbuUk7g9Cqem4vl9ZETT7U9F3S7moLwYWSVz57AzeTAov3I6QsWjyx7hJwuoJIS\nGM4EromsHGq8djsDC0n6aXR5GbSRNkAfwxlkH8M7yBb7peTKTSuRr+/urQT2phz7imR68B9kRceb\nJP0jcnK175IjaycBV/ZrbDRm9XOsAAAKxElEQVQPkV9J0oPk2eJ3KaOBI+JZSYdKeiAirmjrhRiD\nSsAmIm4pDZlPkwfFL0fE55tutxF5ULwqOjC6u6o5Gvtt9zrVub+ATCU8qizf+za5RuQDEfFkRGxG\ntkYPI2dbvKX5zpHlge8Dfi1pqchSrWXJNR/3j5yL5WByVaFhza8+HJJeSJaBTSZTMdPJkbLbkuWe\ne5dUVEsDVsqZzlFkymn3yNK+48mg9A7yoFgb8+ljeEtEHEfmd/9NnsUsS45YfldE3NbKY5TAvgNZ\nLnkaecb3KHmGeJKkU8k018fI9OCrmvZvo3LAaZTgXkZWKk2kTJtbAvt+5Ajd532ee10jPaqc5306\n+RxnAf9QjuZFOY/PuWT544gFduiNOveeb7krR+Y9Ezml51FkDexsss75vKbbrRNZfz7fnFxEfK+c\nHt+gXPnkK2QN8WmS7iFnHNwthqgT76bIqWbfSzmbiIi3l1bOv8iFNl4XbZYBxn+XFn5LOcXAUiP9\n5emmCn0M3y2v6eeBGyPiS20+zqvJztN3kDXsbyfHXCxH1smvR54ZvYCseGmebnkp8n1Yi5zsbZfy\n/73kgeALypGta5PjNEYsPThSlJ3kB0raorTg/5esJJqrLEk9iDxTrzzdQ6c4LdNlygFKe5KrCe0T\nEd+Q9CjZGvpj0+32BA6S9K6IeHCwbUZWKRxJtojXA+4gSwEXIk+D21odqJPKWcRT5GpHa5Pzhv+Q\nPDVtuwywbLt/aeElDDFjZK+p2MdwhbJTunL+upwBnBgR+5arliIbG9uQC5fsE7lwy1KR9d7XlXTi\nSWQn6ANN+3hlSQ2eQS5k8RfldBf3kUsbnkaWt46vS+dpg57r4F6OnLiv0cH8W+VMnGeT40x2jQ6P\nPK2qF0ohezYto6x7/QSZb74H+Fr5UHyfbC1dIGkD5YIFRwGHDRXYGyLiKrKqYTq52MRXI2LqWAjs\nTe4lR+WdTuYjj48KywBWERE/IBdlGPF+hZHS1MfwbORya8eR86LvDLxdZQm6qLhQOEDkyk4bKecq\nh2xgrEu22veOLOPbhmx1v7Tc5jYy5fNfI0gjK4D+D9i6NEyeiZz0aw1yGuNH6hbYYV7Z8irkalbN\no3RXi1wjYA8ytToqgR2clukaZXnUl4AjIgcXPUQGuU9J+n5EfFvSs2Rp4P3kYs0tfRBKy2kCWWmz\nHiUN2OGn0rbSej+dnEelL4ZYQamN7Q97ybOxLHKBkaPIQLt7SUEdD5xCplF+ScXqi9LhOjkiTo6I\n1SXdIOnSiNhF0g/IypsdJc0kGyQfiYgHS2NkqDnVv6ucVuLMkua5ieyA7dQ86GNKSYdNIBto5wE3\nldTUScC9kj4T85keZCQ5LdM9/cujvgFcRb7mH5D0kpI/fgK4O9pcCLd8sa6NMTR8u1nk/NQjnm+s\niw72MQS5GMTCEXF8RGwgaYZyNa+9lGMvtiGrPT4czw1QqvS5Kv1JE8ilGr9Ppgcrn1H0ktKAelY5\nh8zLyAbadOAPZJnziE1ON5i5PZCW6angPp/yqBWAcyJXUkfS+8lVka6IprUm2xVtzmVtvWG4fQwl\nfXOPcvj79yQtFBHHRsT6km6U9I3I9Xd/qKZl8Fo9Cyx9AJsC90QLi7/0IuVsj7uS4wxOIctzO7LI\nRqeMydZePz0V3Js6wtaOiOml4/OzwMOSXhg53PoB8ui+CGPkKG9jW7Q5fUFpfc8pwegRcjDZVeUg\n8fGIWE/S7SVVuC3DHGQTNVzLeCCRa6C+BJjTfAbVXOU02sIt984bojxqMXLGxv1jBOcWt97XTh9D\nxLy5Yj5Bzucyk1yV6YwS4D8REWuqzE80VtN7Y1EMMC/OWAns4JZ7R/VCeZQtWEoq5jiyqmMLcoT0\n0+TEalNLiuZjEfHLUdxN64JeKIXsmeDerzyqMU/5vPIo5XS8/ynlaGYjYRY54vl15AjKdYBzyBHD\nR5KpGquhsR/ae6TOXWkh+pVHSZpGzgC5UkTc4cBuIykiZkUOjd8EuKCMg/g6OXr4xlKmOyqr8Fh3\nzSEqX0ZLT7Tce6U8yhZYtwCHlAbITuT4i3thbOWJrXPcodpBvVAeZQusq8hFNrYHPukce/25Q7WD\neqE8yhZMpbLj68pFYeb4M1l/brl32Fgvj7IF3lzwZ3JB4Ja72QLEQX3BMbcH3moHdzOzFrnO3cys\nhpxzNzOrIefczcxqqBfSMj0xQtXMbCyJFv5VIWkrSXdImlnmyur/97dK+p2kOZJ2qbJNt9xtzJO0\nNDkqGXLiuLk8N+f6Bo050ptuvxpwaUS8buT20hYknayWkTQeOIucN2sWMF3StH4TIN4L7Ecu/1mJ\ng7uNeRHxT3JyLiR9HHgiIj4zqjtlC7QOp2U2AGY2VteSdBEwCZgX3BsLtJSFZSpxWsZ6mqSjJd1a\nLu8b4O+rSfq9pHUlTZB0elnj9GZJB5bbbC7pWkmXlVPj80f+mVgv6WvhIungsuxi43Jwv80tz/OX\ny5xVrhsWt9ytZ0l6I7An8Abys3yDpOsoE8mV9XUvBPYpC7scBjxU1jhdGPiNpMZSjOsCawEPlus3\njIjfjOwzsl7RSilkREwl5/ofUQ7u1sveAnynseqWpCuAjYEfAS8FLgd2iIg/ldtvCbxa0uTy+5LA\n6uXn30TE38p2biLnZHdwtwF1OC1zP7Bi0+8rlOuGxcHd6upfwN+AjYBGcBdwWERc23xDSZsDzzRd\nNRd/N2wQHZ5pYjqwuqSVyaA+GdhjuBt1zt162fXAjpIWlfQCshPq+vK3Z8rvB0rarVx3NXCYpAmQ\n00hLWnSkd9p631yi8mUoETEHOJz8fP4RuDgibpN0gqTtASS9QdIsctrzcyTdNtR23TqxnlWWV/wW\n2fIBOLvk1lcrf39C0rbANZKeJJfAezm5khfAQ+QBwKwlnR7EFBFXkesCNF93XNPP08l0TWXyRHZm\nZq3ZbIUtKwfOa2f9aFSWWnTL3cysRb0w/YCDu5lZizwrpJlZDXmxDjOzGnJaxsyshhzczcxqqBeq\nDB3czcxa5Ja7mVkNuVrGzKyG5sbYX0XVwd3MrEXOuZuZ1ZBz7mZmNeScu5lZDfU5LWNmVj9uuZuZ\n1ZCrZczMashpGTOzGnJaxsyshtxyNzOrIbfczcxqaG7MHe1dGJKDu5lZizz9gJlZDXn6ATOzGnLL\n3cyshlwtY2ZWQ66WMTOrIU8/YGZWQ865m5nVkHPuZmY15Ja7mVkNuc7dzKyG3HI3M6shV8uYmdVQ\nL3SojhvtHTAz6zURUflShaStJN0haaakKQP8fWFJ3y5//62klYbapoO7mVmLooV/Q5E0HjgLeCew\nJrC7pDX73ewA4NGIWA04A/j0UNt1cDcza1GHW+4bADMj4q6ImA1cBEzqd5tJwNfLz5cCm0nSYBt1\ncDcza1FfROVLBcsD9zX9PqtcN+BtImIO8G9g6cE26g5VM7MWzZl9/6Ct5maSDgYObrpqakRM7fxe\nPZ+Du5lZF5VAPlgwvx9Ysen3Fcp1A91mlqQJwJLAPwd7XKdlzMxG13RgdUkrS5oITAam9bvNNGDf\n8vMuwE9iiIS+W+5mZqMoIuZIOhy4GhgPnBcRt0k6AZgREdOArwDfkDQTeIQ8AAxKvTCM1szMWuO0\njJlZDTm4m5nVkIO7mVkNObibmdWQg7uZWQ05uJuZ1ZCDu5lZDTm4m5nV0P8DJRxFdfX13jUAAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6CWwxX2aTBla",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Layer normalization"
      ]
    },
    {
      "metadata": {
        "id": "xPzmk6T3TD_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall from our [CNN notebook](https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/11_Convolutional_Neural_Networks.ipynb) that we used batch normalization to deal with internal covariant shift. Our activations will experience the same issues with RNNs but we will use a technique known as [layer normalization](https://arxiv.org/abs/1607.06450) (layernorm) to maintain zero mean unit variance on the activations. \n",
        "\n",
        "With layernorm it's a bit different from batchnorm. We compute the mean and var for every single sample (instead of each hidden dim) for each layer independently and then do the operations on the activations before they go through the nonlinearities. PyTorch's [LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) class abstracts all of this for us when we feed in inputs to the layer."
      ]
    },
    {
      "metadata": {
        "id": "tZTdk6OyTGq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$ LN = \\frac{a - \\mu_{L}}{\\sqrt{\\sigma^2_{L} + \\epsilon}}  * \\gamma + \\beta $\n",
        "\n",
        "where:\n",
        "* $a$ = activation | $\\in \\mathbb{R}^{NXH}$ ($N$ is the number of samples, $H$ is the hidden dim)\n",
        "* $ \\mu_{L}$ = mean of input| $\\in \\mathbb{R}^{NX1}$\n",
        "* $\\sigma^2_{L}$ = variance of input | $\\in \\mathbb{R}^{NX1}$\n",
        "* $epsilon$ = noise\n",
        "* $\\gamma$ = scale parameter (learned parameter)\n",
        "* $\\beta$ = shift parameter (learned parameter)"
      ]
    },
    {
      "metadata": {
        "id": "RAZGISTXTGnV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/layernorm.png\" width=400>\n",
        "\n",
        "The most useful location to apply layernorm will be inside the RNN on the activations before the non-linearities. However, this is a bit involved and though PyTorch has a [LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) class, they do not have an RNN that has built in layernorm yet. You could implement the RNN yourself and manually add layernorm by following a similar setup like below.\n",
        "\n",
        "```python\n",
        "# Layernorm\n",
        "for t in range(seq_size):\n",
        "    # Normalize over hidden dim\n",
        "    layernorm = nn.LayerNorm(args.hidden_dim)\n",
        "    # Activating the module\n",
        "    a = layernorm(x)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "1YHneO3SStOp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO"
      ]
    },
    {
      "metadata": {
        "id": "gGHaKTe1SuEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- attn visualization isn't always great\n",
        "- bleu score\n",
        "- ngram-overlap\n",
        "- perplexity\n",
        "- beamsearch\n",
        "- hierarchical softmax\n",
        "- hierarchical attention\n",
        "- Transformer networks\n",
        "- attention interpretability is hit/miss\n"
      ]
    }
  ]
}